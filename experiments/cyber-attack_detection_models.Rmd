---
title: "Evaluation of the performance cyber-attack detection models for various representations"
author: "Hidden for the time of the double-blind review process"
date: "`r Sys.Date()`"
output:
  html_notebook:
    df_print: paged
    fig_height: 10
    fig_width: 10
    rows.print: 10
    css: doc.css
  html_document:
    df_print: paged
    fig_height: 10
    fig_width: 10
    rows.print: 10
    css: doc.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(width = 120)  

# installation of the required packages (uncomment the lines below):
# install.packages(c("data.table", "xgboost", "caTools", "Ckmeans.1d.dp", 
#                    "ggplot2", "lubridate", "fasttime", "Matrix", "proxy", "glmnet"))

library(data.table)
library(ggplot2)
library(lubridate)
library(fasttime)
library(caTools)

library(proxy)
library(xgboost)
library(glmnet)

n_cores <- 8

# local data paths
data_dir <- ""

# an auxiliary function for constructing traces from event logs
construct_process_trace <- function(event_dt) {
  event_dt[, {
    event_chain <- paste(PROCESS_uid, SYSCALL_syscall, SYSCALL_success, 
                         sep = "_")
    list(trace = paste(event_chain, collapse = ","),
         trace_length = length(event_chain))
  }]
}

# an auxiliary function for compacting traces
compact_traces <- function(trace_dt, unique_action_ids, show_progress = TRUE) {
  trace_dt[, compacted_trace := copy(trace)]
  
  trace_dt[, compacted_trace := gsub("root_close_yes,root_openat_yes",
                                     "root_close_openat_yes", 
                                     compacted_trace)]
  trace_dt[, compacted_trace := gsub("(,root_close_openat_yes){2,}", 
                                     ",multi_root_close_openat_yes",
                                     compacted_trace)]
  trace_dt[, compacted_trace := gsub("^root_close_openat_yes,multi_root_close_openat_yes",
                                     "multi_root_close_openat_yes",
                                     compacted_trace)]
  trace_dt[, compacted_trace := gsub("^root_close_openat_yes,root_close_openat_yes",
                                     "multi_root_close_openat_yes",
                                     compacted_trace)]
  
  for(action in unique_action_ids) {
    trace_dt[, compacted_trace := gsub(paste0("(,", action, "){2,}"), 
                                       paste0(",multi_", action), 
                                       compacted_trace)]
    trace_dt[, compacted_trace := gsub(paste0("^", action, ",multi_", action), 
                                       paste0("multi_", action), 
                                       compacted_trace)]
    trace_dt[, compacted_trace := gsub(paste0("^", action, ",", action), 
                                       paste0("multi_", action), 
                                       compacted_trace)]
    if(show_progress) print(action)
  }
  trace_dt[, uniqueN(compacted_trace)]
  trace_dt[, compacted_trace_length := sapply(strsplit(compacted_trace, ","), length)]
  trace_dt
}

# an auxiliary function for creating an ML-friendly representation from selected traces
create_trace_representation <- function(dt, traces) {
  
  trace_list <- strsplit(traces, ",")
  trace_sizes <- sapply(trace_list, length)
  data_trace_list <- strsplit(dt[, compacted_trace], ",")
  data_trace_sizes <- sapply(data_trace_list, length)
  dist_matrix <- proxy::dist(trace_list, data_trace_list, 
                             method = "Levenshtein")
  norm_matrix <- matrix(trace_sizes[rep(1:length(trace_sizes), length(data_trace_sizes))] + 
                          data_trace_sizes[rep(1:length(data_trace_sizes), each = length(trace_sizes))], 
                      ncol = length(data_trace_sizes))
  dist_matrix <- as.matrix(dist_matrix)/norm_matrix
  as.list(apply(dist_matrix, 1, min))
}

# an auxiliary function for constructing an XGBoost model
construct_xgb_from_traces <- function(training_dt, test_dt, n_trees = 1000, params_xgb = list()) {

  # data type conversion
  validation_set_idx <- sort(sample(nrow(training_dt), round(nrow(training_dt)/20)))
  xgbMatrix_tr <- xgb.DMatrix(as.matrix(training_dt[-validation_set_idx, !c("time_window_id","is_attack")]), 
                             label = training_dt[-validation_set_idx, as.integer(is_attack)])
  xgbMatrix_val <- xgb.DMatrix(as.matrix(training_dt[validation_set_idx, !c("time_window_id","is_attack")]), 
                             label = training_dt[validation_set_idx, as.integer(is_attack)])
  xgbMatrix_te <- xgb.DMatrix(as.matrix(test_dt[, !c("time_window_id","is_attack")]), 
                             label=test_dt[, as.integer(is_attack)])
  
  # model construction
  times <- system.time({
    xgboostModel <- xgb.train(data = xgbMatrix_tr, 
                           params = params_xgb, 
                           nrounds = n_trees, 
                           print_every_n = round(n_trees/10),
                           watchlist = list(train = xgbMatrix_tr, 
                                            validation = xgbMatrix_val, 
                                            test = xgbMatrix_te))
  })
  print(as.numeric(times)[1:3])
  xgboostModel
}

construct_glm_from_traces <- function(training_dt, test_dt, params_glm = list()) {

  times <- system.time({
    glm_model = glmnet::cv.glmnet(as.matrix(training_dt[, !c("time_window_id","is_attack")]), 
                                  training_dt[, as.integer(is_attack)], 
                                  family = "binomial", 
                                  type.measure="auc", 
                                  nfolds = params_glm$nfolds, 
                                  weights = params_glm$ws_glmnet,
                                  alpha = params_glm$alpha, 
                                  nlambda = params_glm$nlambda)
  })
  print(as.numeric(times)[1:3])
  
  # test score: 
  preds_te = predict(glm_model, as.matrix(test_dt[, !c("time_window_id","is_attack")]), 
                     type="response", s=glm_model$lambda.min)
  # produce results:
  list(model = glm_model, te_preds = preds_te)
}
```

### The plan:

1. Loading all data.
2. Constructing ML-friendly representations of time windows from the model training and evaluation parts of data.
3. Conducting the initial experiments with ML models for predicting cyber attacks.  

```{r processed_data_loading, results='hide'}
# loading the preprocess data for the project
load(file = file.path("process_data_v2.RData"))

# loading data from the process discovery part
# this file contains: variant_dt, cluster_reps, largest_variants, extreme_variants 
load(file = file.path("selected_variants.RData"))
head(variant_dt)

# dealing with empty values in the SYSCALL_success column
process_discovery_data[SYSCALL_success == "", SYSCALL_success := "NA"]
model_training_data[SYSCALL_success == "", SYSCALL_success := "NA"]
test_data[SYSCALL_success == "", SYSCALL_success := "NA"]

# setting the table keys for efficiency
setkey(process_discovery_data, time_window_id, SYSCALL_timestamp)
setkey(model_training_data, time_window_id, SYSCALL_timestamp)
setkey(test_data, time_window_id, SYSCALL_timestamp)
```

### Constructing ML-friendly representations of time windows from the model training and evaluation parts of data:

```{r constructing_reps, warning=FALSE, fig.hold='hold', out.width="100%", fig.width=12}
model_training_data[, time_window_id_SYSCALL_pid := paste0(time_window_id, "_", SYSCALL_pid)]
test_data[, time_window_id_SYSCALL_pid := paste0(time_window_id, "_", SYSCALL_pid)]

unique_action_ids <- model_training_data[, unique(paste(PROCESS_uid, 
                                                        SYSCALL_syscall, 
                                                        SYSCALL_success, sep = "_"))]
model_training_trace_dt <- model_training_data[, c(construct_process_trace(.SD),
                                                   attack = unique(is_attack)),
                                               by = time_window_id_SYSCALL_pid]

# The number of traces before compacting:
model_training_trace_dt[, uniqueN(trace)]
model_training_trace_dt <- compact_traces(model_training_trace_dt, unique_action_ids, 
                                          show_progress = FALSE)
# The number of traces after compacting:
model_training_trace_dt[, uniqueN(compacted_trace)]

test_trace_dt <- test_data[, c(construct_process_trace(.SD),
                               attack = unique(is_attack)),
                           by = time_window_id_SYSCALL_pid]
# The number of traces in test data before compacting:
test_trace_dt[, uniqueN(trace)]
test_trace_dt <- compact_traces(test_trace_dt, unique_action_ids, 
                                show_progress = FALSE)
# The number of traces in test data after compacting:
test_trace_dt[, uniqueN(compacted_trace)]

# The number of common traces between test and training data
sum(test_trace_dt[, unique(compacted_trace)] %chin% model_training_trace_dt[, unique(compacted_trace)])
# The number of common traces between test and process discovery data
sum(test_trace_dt[, unique(compacted_trace)] %chin% variant_dt[, compacted_trace])
# The number of common traces between training and process discovery data
sum(model_training_trace_dt[, unique(compacted_trace)] %chin% variant_dt[, compacted_trace])
```

```{r data_save1, echo=FALSE}
save(variant_dt, model_training_trace_dt, test_trace_dt,
     file = "compacted_trace_data.RData")
```

### Setting hyperparameters of the prediction models

```{r hyperparams}
model_training_trace_dt[, time_window_id := sapply(strsplit(time_window_id_SYSCALL_pid, "_"), first)]
test_trace_dt[, time_window_id := sapply(strsplit(time_window_id_SYSCALL_pid, "_"), first)]

tr_data_labels <- model_training_trace_dt[, .(is_attack = first(attack)), keyby = time_window_id]
prior_probs <- tr_data_labels[, .(prob = .N/nrow(tr_data_labels)), keyby = is_attack]

# hyperparameters for XGBoost:
n_trees <- 1000
params_xgb <- list(booster = "gbtree", 
                  objective = "binary:logistic",
                  eta = 0.01, 
                  max_depth = 8, 
                  lambda = 1.0, alpha = 10.0, 
                  subsample = 1.0, colsample_bytree = 0.8,
                  base_score = prior_probs[is_attack == TRUE, prob],
                  nthread = n_cores)

# hyperparameters for GLMnet:
params_glm = list(alpha = 0.9, nfolds = 10, nlambda = 200, 
                  ws_glmnet = prior_probs[tr_data_labels, on = "is_attack"][, 1/prob])
```


### Constructing training and test sets using all variants present in the training data

```{r ml_representation_baseline, warning=FALSE, fig.hold='hold', out.width="100%", fig.width=12}
# representation by all compacted variants from the training data (no filtering)
unique_training_traces <- model_training_trace_dt[, unique(compacted_trace)]

training_dt <- model_training_trace_dt[, {selected_variants = (compacted_trace %chin% unique_training_traces);
                                          c(as.list(unique_training_traces %chin% compacted_trace),
                                           n_of_traces = .N,
                                           min_compacted_length = min(compacted_trace_length),
                                           mean_compacted_length = mean(compacted_trace_length),
                                           max_compacted_length = max(compacted_trace_length),
                                           min_length = min(trace_length),
                                           mean_length = mean(trace_length),
                                           max_length = max(trace_length),
                                           n_of_traces_selected = sum(selected_variants),
                                           min_compacted_length_selected = ifelse(any(selected_variants), min(compacted_trace_length[selected_variants]), 0L),
                                           mean_compacted_length_selected = ifelse(any(selected_variants), mean(compacted_trace_length[selected_variants]), 0),
                                           max_compacted_length_selected = ifelse(any(selected_variants), max(compacted_trace_length[selected_variants]), 0L),
                                           min_length_selected = ifelse(any(selected_variants), min(trace_length[selected_variants]), 0L),
                                           mean_length_selected = ifelse(any(selected_variants), mean(trace_length[selected_variants]), 0),
                                           max_length_selected = ifelse(any(selected_variants), max(trace_length[selected_variants]), 0L),
                                           tot_variant_length = sum(trace_length),
                                           tot_compacted_variant_length = sum(compacted_trace_length),
                                           tot_variant_length_selected = sum(trace_length[selected_variants]),
                                           tot_compacted_variant_length_selected = sum(compacted_trace_length[selected_variants]),
                                           is_attack = first(attack))},
                                       keyby = time_window_id]
setnames(training_dt, 
         1:(length(unique_training_traces)+1), 
         c("time_window_id", paste0("variant_", 1:length(unique_training_traces))))

test_dt <- test_trace_dt[, {selected_variants = (compacted_trace %chin% unique_training_traces);
                                          c(as.list(unique_training_traces %chin% compacted_trace),
                                           n_of_traces = .N,
                                           min_compacted_length = min(compacted_trace_length),
                                           mean_compacted_length = mean(compacted_trace_length),
                                           max_compacted_length = max(compacted_trace_length),
                                           min_length = min(trace_length),
                                           mean_length = mean(trace_length),
                                           max_length = max(trace_length),
                                           n_of_traces_selected = sum(selected_variants),
                                           min_compacted_length_selected = ifelse(any(selected_variants), min(compacted_trace_length[selected_variants]), 0L),
                                           mean_compacted_length_selected = ifelse(any(selected_variants), mean(compacted_trace_length[selected_variants]), 0),
                                           max_compacted_length_selected = ifelse(any(selected_variants), max(compacted_trace_length[selected_variants]), 0L),
                                           min_length_selected = ifelse(any(selected_variants), min(trace_length[selected_variants]), 0L),
                                           mean_length_selected = ifelse(any(selected_variants), mean(trace_length[selected_variants]), 0),
                                           max_length_selected = ifelse(any(selected_variants), max(trace_length[selected_variants]), 0L),
                                           tot_variant_length = sum(trace_length),
                                           tot_compacted_variant_length = sum(compacted_trace_length),
                                           tot_variant_length_selected = sum(trace_length[selected_variants]),
                                           tot_compacted_variant_length_selected = sum(compacted_trace_length[selected_variants]),
                                           is_attack = first(attack))},
                         keyby = time_window_id]

setnames(test_dt, 
         1:(length(unique_training_traces)+1), 
         c("time_window_id", paste0("variant_", 1:length(unique_training_traces))))
```

### Evaluation of the XGBoost model trained on the representation by all variants from the training data

```{r xgb_baseline, warning=FALSE, fig.hold='hold', out.width="100%", fig.width=12}
# building an XGBoost model for the representation by all compacted variants from the training data
xgboostModel <- construct_xgb_from_traces(training_dt, test_dt,
                                          n_trees = n_trees, 
                                          params_xgb = params_xgb)

# test score: 
preds <- predict(xgboostModel, as.matrix(test_dt[, !c("time_window_id","is_attack")]))
print(colAUC(preds, test_dt[, is_attack]))

# confusion matrix
table(preds > training_dt[, mean(is_attack)], test_dt[, is_attack] > 0)

# estimation of the feature importance
importance_matrix <- xgb.importance(colnames(training_dt[, !c("time_window_id","is_attack")]), 
                                    model = xgboostModel)
feat_importance_plot = xgb.ggplot.importance(importance_matrix, 
                                            measure = "Gain", 
                                            rel_to_first = TRUE, 
                                            top_n = 20)
feat_importance_plot + ylab("Gain")

importance_matrix
```

```{r glm_baseline, warning=FALSE, fig.hold='hold', out.width="100%", fig.width=12}
# building model GLMnet model for the representation by all compacted variants from the training data
glmnetModel <- construct_glm_from_traces(training_dt, test_dt,
                                         params_glm = params_glm)

# test score: 
preds <- glmnetModel$te_preds
print(colAUC(preds, test_dt[, is_attack]))

# confusion matrix
table(preds > 0.5, test_dt[, is_attack] > 0)

# estimation of the feature importance
coefs <- coef(glmnetModel$model, s = "lambda.min")
sum(coefs != 0)
mean(coefs != 0)
```

```{r model_save1}
save(training_dt, test_dt, glmnetModel, xgboostModel, params_glm, params_xgb,
     file = "data_and_models_xgb_glm_all_training_variants.RData")
```


### Constructing training and test sets using all variants discovered in the process discovery part of data

```{r ml_representation_baseline2, warning=FALSE, fig.hold='hold', out.width="100%", fig.width=12}
training_dt <- model_training_trace_dt[, {selected_variants = (compacted_trace %chin% variant_dt[, compacted_trace]);
                                          c(as.list(variant_dt[, compacted_trace] %chin% compacted_trace),
                                           n_of_traces = .N,
                                           min_compacted_length = min(compacted_trace_length),
                                           mean_compacted_length = mean(compacted_trace_length),
                                           max_compacted_length = max(compacted_trace_length),
                                           min_length = min(trace_length),
                                           mean_length = mean(trace_length),
                                           max_length = max(trace_length),
                                           n_of_traces_selected = sum(selected_variants),
                                           min_compacted_length_selected = ifelse(any(selected_variants), min(compacted_trace_length[selected_variants]), 0L),
                                           mean_compacted_length_selected = ifelse(any(selected_variants), mean(compacted_trace_length[selected_variants]), 0),
                                           max_compacted_length_selected = ifelse(any(selected_variants), max(compacted_trace_length[selected_variants]), 0L),
                                           min_length_selected = ifelse(any(selected_variants), min(trace_length[selected_variants]), 0L),
                                           mean_length_selected = ifelse(any(selected_variants), mean(trace_length[selected_variants]), 0),
                                           max_length_selected = ifelse(any(selected_variants), max(trace_length[selected_variants]), 0L),
                                           tot_variant_length = sum(trace_length),
                                           tot_compacted_variant_length = sum(compacted_trace_length),
                                           tot_variant_length_selected = sum(trace_length[selected_variants]),
                                           tot_compacted_variant_length_selected = sum(compacted_trace_length[selected_variants]),
                                           is_attack = first(attack))},
                                       keyby = time_window_id]
setnames(training_dt, 
         1:(nrow(variant_dt)+1), 
         c("time_window_id", paste0("trace_", 1:nrow(variant_dt))))

test_dt <- test_trace_dt[, {selected_variants = (compacted_trace %chin% variant_dt[, compacted_trace]);
                                          c(as.list(variant_dt[, compacted_trace] %chin% compacted_trace),
                                           n_of_traces = .N,
                                           min_compacted_length = min(compacted_trace_length),
                                           mean_compacted_length = mean(compacted_trace_length),
                                           max_compacted_length = max(compacted_trace_length),
                                           min_length = min(trace_length),
                                           mean_length = mean(trace_length),
                                           max_length = max(trace_length),
                                           n_of_traces_selected = sum(selected_variants),
                                           min_compacted_length_selected = ifelse(any(selected_variants), min(compacted_trace_length[selected_variants]), 0L),
                                           mean_compacted_length_selected = ifelse(any(selected_variants), mean(compacted_trace_length[selected_variants]), 0),
                                           max_compacted_length_selected = ifelse(any(selected_variants), max(compacted_trace_length[selected_variants]), 0L),
                                           min_length_selected = ifelse(any(selected_variants), min(trace_length[selected_variants]), 0L),
                                           mean_length_selected = ifelse(any(selected_variants), mean(trace_length[selected_variants]), 0),
                                           max_length_selected = ifelse(any(selected_variants), max(trace_length[selected_variants]), 0L),
                                           tot_variant_length = sum(trace_length),
                                           tot_compacted_variant_length = sum(compacted_trace_length),
                                           tot_variant_length_selected = sum(trace_length[selected_variants]),
                                           tot_compacted_variant_length_selected = sum(compacted_trace_length[selected_variants]),
                                           is_attack = first(attack))},
                         keyby = time_window_id]
setnames(test_dt, 
         1:(nrow(variant_dt)+1), 
         c("time_window_id", paste0("trace_", 1:nrow(variant_dt))))
```

### Evaluation of the XGBoost model trained on the representation only by variants discovered in the process discovery part of data

```{r xgb_baseline2, warning=FALSE, fig.hold='hold', out.width="100%", fig.width=12}
# building model 
xgboostModel <- construct_xgb_from_traces(training_dt, test_dt,
                                          n_trees = n_trees, 
                                          params_xgb = params_xgb)

# test score: 
preds <- predict(xgboostModel, as.matrix(test_dt[, !c("time_window_id","is_attack")]))
print(colAUC(preds, test_dt[, is_attack]))

# confusion matrix
table(preds > training_dt[, mean(is_attack)], test_dt[, is_attack] > 0)

# estimation of the feature importance
importance_matrix <- xgb.importance(colnames(training_dt[, !c("time_window_id","is_attack")]), 
                                    model = xgboostModel)
feat_importance_plot = xgb.ggplot.importance(importance_matrix, 
                                            measure = "Gain", 
                                            rel_to_first = TRUE, 
                                            top_n = 20)
feat_importance_plot + ylab("Gain")

importance_matrix
```

```{r glm_baseline2, warning=FALSE, fig.hold='hold', out.width="100%", fig.width=12}
# building model 
glmnetModel <- construct_glm_from_traces(training_dt, test_dt,
                                         params_glm = params_glm)

# test score: 
preds <- glmnetModel$te_preds
print(colAUC(preds, test_dt[, is_attack]))

# confusion matrix
table(preds > 0.5, test_dt[, is_attack] > 0)

# estimation of the feature importance
coefs <- coef(glmnetModel$model, s = "lambda.min")
sum(coefs != 0)
mean(coefs != 0)
```

```{r model_save2}
save(training_dt, test_dt, glmnetModel, xgboostModel, params_glm, params_xgb,
     file = "data_and_models_xgb_glm_all_proc_discovery_variants.RData")
```

### Constructing training and test sets using distances to selected variants discovered in the process discovery part of data

```{r ml_representation, warning=FALSE, fig.hold='hold', out.width="100%", fig.width=12}
selected_traces <- variant_dt[rbind(extreme_variants, cluster_reps, largest_variants)[, unique(index)], 
                              compacted_trace]

training_dt <- model_training_trace_dt[, {selected_variants = (compacted_trace %chin% selected_traces);
                                          c(create_trace_representation(.SD, selected_traces),
                                           n_of_traces = .N,
                                           min_compacted_length = min(compacted_trace_length),
                                           mean_compacted_length = mean(compacted_trace_length),
                                           max_compacted_length = max(compacted_trace_length),
                                           min_length = min(trace_length),
                                           mean_length = mean(trace_length),
                                           max_length = max(trace_length),
                                           n_of_traces_selected = sum(selected_variants),
                                           min_compacted_length_selected = ifelse(any(selected_variants), min(compacted_trace_length[selected_variants]), 0L),
                                           mean_compacted_length_selected = ifelse(any(selected_variants), mean(compacted_trace_length[selected_variants]), 0),
                                           max_compacted_length_selected = ifelse(any(selected_variants), max(compacted_trace_length[selected_variants]), 0L),
                                           min_length_selected = ifelse(any(selected_variants), min(trace_length[selected_variants]), 0L),
                                           mean_length_selected = ifelse(any(selected_variants), mean(trace_length[selected_variants]), 0),
                                           max_length_selected = ifelse(any(selected_variants), max(trace_length[selected_variants]), 0L),
                                           tot_variant_length = sum(trace_length),
                                           tot_compacted_variant_length = sum(compacted_trace_length),
                                           tot_variant_length_selected = sum(trace_length[selected_variants]),
                                           tot_compacted_variant_length_selected = sum(compacted_trace_length[selected_variants]),
                                           is_attack = first(attack))},
                                       keyby = time_window_id]
setnames(training_dt, 
         1:(length(selected_traces)+1), 
         c("time_window_id", paste0("trace_", 1:length(selected_traces))))

test_dt <- test_trace_dt[, {selected_variants = (compacted_trace %chin% selected_traces);
                                          c(create_trace_representation(.SD, selected_traces),
                                           n_of_traces = .N,
                                           min_compacted_length = min(compacted_trace_length),
                                           mean_compacted_length = mean(compacted_trace_length),
                                           max_compacted_length = max(compacted_trace_length),
                                           min_length = min(trace_length),
                                           mean_length = mean(trace_length),
                                           max_length = max(trace_length),
                                           n_of_traces_selected = sum(selected_variants),
                                           min_compacted_length_selected = ifelse(any(selected_variants), min(compacted_trace_length[selected_variants]), 0L),
                                           mean_compacted_length_selected = ifelse(any(selected_variants), mean(compacted_trace_length[selected_variants]), 0),
                                           max_compacted_length_selected = ifelse(any(selected_variants), max(compacted_trace_length[selected_variants]), 0L),
                                           min_length_selected = ifelse(any(selected_variants), min(trace_length[selected_variants]), 0L),
                                           mean_length_selected = ifelse(any(selected_variants), mean(trace_length[selected_variants]), 0),
                                           max_length_selected = ifelse(any(selected_variants), max(trace_length[selected_variants]), 0L),
                                           tot_variant_length = sum(trace_length),
                                           tot_compacted_variant_length = sum(compacted_trace_length),
                                           tot_variant_length_selected = sum(trace_length[selected_variants]),
                                           tot_compacted_variant_length_selected = sum(compacted_trace_length[selected_variants]),
                                           is_attack = first(attack))},
                         keyby = time_window_id]
setnames(test_dt, 
         1:(length(selected_traces)+1), 
         c("time_window_id", paste0("trace_", 1:length(selected_traces))))
```

### Saving the representations by distances to selected variants discovered in the process discovery part of data

```{r ml_representation_save, warning=FALSE}
save(training_dt, test_dt, selected_traces,
     file = "training_and_test_data_distance_from_selected_variants_rep_v2.RData")
```

### Evaluation of the XGBoost model trained on the representation by distances to selected variants discovered in the process discovery part of data

```{r xgb_model1, warning=FALSE, fig.hold='hold', out.width="100%", fig.width=12}
# building model 
xgboostModel <- construct_xgb_from_traces(training_dt, test_dt,
                                          n_trees = n_trees, 
                                          params_xgb = params_xgb)

# test score: 
preds <- predict(xgboostModel, as.matrix(test_dt[, !c("time_window_id","is_attack")]))
print(colAUC(preds, test_dt[, is_attack]))

# confusion matrix
table(preds > training_dt[, mean(is_attack)], test_dt[, is_attack] > 0)

# estimation of the feature importance
importance_matrix <- xgb.importance(colnames(training_dt[, !c("time_window_id","is_attack")]), 
                                    model = xgboostModel)
feat_importance_plot = xgb.ggplot.importance(importance_matrix, 
                                            measure = "Gain", 
                                            rel_to_first = TRUE, 
                                            top_n = 20)
feat_importance_plot + ylab("Gain")

importance_matrix
```
```{r glm_baseline3, warning=FALSE, fig.hold='hold', out.width="100%", fig.width=12}
# building model 
glmnetModel <- construct_glm_from_traces(training_dt, test_dt,
                                         params_glm = params_glm)

# test score: 
preds <- glmnetModel$te_preds
print(colAUC(preds, test_dt[, is_attack]))

# confusion matrix
table(preds > 0.5, test_dt[, is_attack] > 0)

# estimation of the feature importance
coefs <- coef(glmnetModel$model, s = "lambda.min")
sum(coefs != 0)
mean(coefs != 0)
coefs
```


### Constructing training and test sets using all __variants__ from the training data (without compacting)

This representation does not use compacting - we check its result to estimate gain from the use of variant compacting.

```{r ml_representation_baseline3, warning=FALSE, fig.hold='hold', out.width="100%", fig.width=12}
# constructing the representation by all variants from the training data (without compacting)
unique_training_traces <- model_training_trace_dt[, unique(trace)]

model_training_trace_dt[, time_window_id := sapply(strsplit(time_window_id_SYSCALL_pid, "_"), first)]
training_dt <- model_training_trace_dt[, c(as.list(unique_training_traces %chin% trace),
                                           n_of_traces = .N,
                                           min_length = min(trace_length),
                                           mean_length = mean(trace_length),
                                           max_length = max(trace_length),
                                           is_attack = first(attack)),
                                       keyby = time_window_id]
setnames(training_dt, 
         1:(length(unique_training_traces)+1), 
         c("time_window_id", paste0("trace_", 1:length(unique_training_traces))))

test_trace_dt[, time_window_id := sapply(strsplit(time_window_id_SYSCALL_pid, "_"), first)]
test_dt <- test_trace_dt[, c(as.list(unique_training_traces %chin% trace),
                             n_of_traces = .N,
                             min_length = min(trace_length),
                             mean_length = mean(trace_length),
                             max_length = max(trace_length),
                             is_attack = first(attack)),
                         keyby = time_window_id]

setnames(test_dt, 
         1:(length(unique_training_traces)+1), 
         c("time_window_id", paste0("trace_", 1:length(unique_training_traces))))
```

### Evaluation of the XGBoost model trained on the representation by all __variants__ from the training data (without compacting)

```{r xgb_baseline3, warning=FALSE, fig.hold='hold', out.width="100%", fig.width=12}
# building model an XGBoost model for the representation by all variants from the training data (without compacting)
xgboostModel <- construct_xgb_from_traces(training_dt, test_dt,
                                          n_trees = n_trees, 
                                          params_xgb = params_xgb)

# test score: 
preds <- predict(xgboostModel, as.matrix(test_dt[, !c("time_window_id","is_attack")]))
print(colAUC(preds, test_dt[, is_attack]))

# confusion matrix
table(preds > training_dt[, mean(is_attack)], test_dt[, is_attack] > 0)

# estimation of the feature importance
importance_matrix <- xgb.importance(colnames(training_dt[, !c("time_window_id","is_attack")]), 
                                    model = xgboostModel)
feat_importance_plot = xgb.ggplot.importance(importance_matrix, 
                                            measure = "Gain", 
                                            rel_to_first = TRUE, 
                                            top_n = 20)
feat_importance_plot + ylab("Gain")

importance_matrix
```
```{r glm_baseline4, warning=FALSE, fig.hold='hold', out.width="100%", fig.width=12}
# building GLMnet model 
glmnetModel <- construct_glm_from_traces(training_dt, test_dt,
                                         params_glm = params_glm)

# test score: 
preds <- glmnetModel$te_preds
print(colAUC(preds, test_dt[, is_attack]))

# confusion matrix
table(preds > 0.5, test_dt[, is_attack] > 0)

# estimation of the feature importance
coefs <- coef(glmnetModel$model, s = "lambda.min")
sum(coefs != 0)
mean(coefs != 0)
```

```{r model_save3}
save(training_dt, test_dt, glmnetModel, xgboostModel, params_glm, params_xgb,
     file = "data_and_models_xgb_glm_all_variants_no_compacting.RData")
```

```{r}

```

