---
title: "Cybersecurity Threat Detection in the Behavior of IoT Devices"
author: "Hidden for the time of the double-blind review process"
date: "`r Sys.Date()`"
output:
  html_notebook:
    df_print: paged
    fig_height: 10
    fig_width: 10
    rows.print: 10
    css: doc.css
  html_document:
    df_print: paged
    fig_height: 10
    fig_width: 10
    rows.print: 10
    css: doc.css
---

### The plan:

1. Loading all data.
2. Extracting statistics regarding PIDs (cases) and syscall types (actions).
3. Computation of basic aggregations and visualization of the results.  

The original source system audit logs are the property of KnowledgePit.ai platform and can be downloaded from:
https://knowledgepit.ai/fedcsis-2023-challenge/

```{r setup, include=FALSE, results=FALSE}
options(width = 120)

# installation of the required packages (uncomment the lines below):
# install.packages(c("data.table", "arules", "arulesSequences", "arulesViz", 
#                    "ggplot2", "lubridate", "fasttime", "Matrix"))

library(data.table)
library(Matrix)
library(arules)
library(arulesSequences)
library(arulesViz)
library(ggplot2)
library(lubridate)
library(fasttime)

library(bupaverse)

n_cores <- 6

# local data paths
data_dir <- "data"
data_dir_tr <- "data/train_data"
data_dir_te <- "data/test_data"

# local file names
training_attacks_file <- "train_files_containing_attacks.txt"
test_attacks_file <- "test_files_containing_attacks.txt"

# getting lists of files with audit logs
training_file_list <- dir(file.path(getwd(), data_dir_tr))
test_file_list <- dir(file.path(getwd(), data_dir_te))
attack_file_names <- c(readLines(file.path(data_dir, training_attacks_file)),
                       readLines(file.path(data_dir, test_attacks_file)))

# custom function definitions
extract_basic_info <- function(logs) {
  n_of_pids <- logs[, uniqueN(SYSCALL_pid)]
  n_of_unique_actions <- logs[, uniqueN(SYSCALL_syscall)]
  n_of_events <- nrow(logs)
  avg_actions_per_pid <- n_of_events/n_of_pids
  actions_per_pid_quants <- logs[, .N, SYSCALL_pid][, quantile(N, c(0, 0.1, 0.25, 0.5, 0.75, 0.9, 1.0))]
  
  list(n_of_pids = n_of_pids,
       n_of_unique_actions = n_of_unique_actions,
       n_of_events = n_of_events,
       avg_actions_per_pid = avg_actions_per_pid,
       actions_per_pid_quants = actions_per_pid_quants
  )
}

getSequenceID <- function(itemsetIDs) {
  sapply(strsplit(itemsetIDs, "_"), function(x) paste0(x[1], "_", x[2]))
}

getTimestamp <- function(itemsetIDs) {
  sapply(strsplit(itemsetIDs, "_"), function(x) as.integer(x[3]))
}

# an auxiliary function for compacting traces
compact_traces <- function(trace_dt, unique_action_ids, show_progress = TRUE) {
  trace_dt[, compacted_trace := copy(trace)]
  
  trace_dt[, compacted_trace := gsub("root_close_yes,root_openat_yes",
                                     "root_close_openat_yes", 
                                     compacted_trace)]
  trace_dt[, compacted_trace := gsub("(,root_close_openat_yes){2,}", 
                                     ",multi_root_close_openat_yes",
                                     compacted_trace)]
  trace_dt[, compacted_trace := gsub("^root_close_openat_yes,multi_root_close_openat_yes",
                                     "multi_root_close_openat_yes",
                                     compacted_trace)]
  trace_dt[, compacted_trace := gsub("^root_close_openat_yes,root_close_openat_yes",
                                     "multi_root_close_openat_yes",
                                     compacted_trace)]
  
  for(action in unique_action_ids) {
    trace_dt[, compacted_trace := gsub(paste0("(,", action, "){2,}"), 
                                       paste0(",multi_", action), 
                                       compacted_trace)]
    trace_dt[, compacted_trace := gsub(paste0("^", action, ",multi_", action), 
                                       paste0("multi_", action), 
                                       compacted_trace)]
    trace_dt[, compacted_trace := gsub(paste0("^", action, ",", action), 
                                       paste0("multi_", action), 
                                       compacted_trace)]
    if(show_progress) print(action)
  }
  trace_dt[, uniqueN(compacted_trace)]
  trace_dt[, compacted_trace_length := sapply(strsplit(compacted_trace, ","), length)]
  trace_dt
}
```

The available data contains `r length(training_file_list) + length(test_file_list)` log files. Each of the files corresponds to 10 minutes of syscall history. In total, `r length(attack_file_names)` log files (`r round(100*length(attack_file_names)/(length(training_file_list) + length(test_file_list)), 2)`\%) correspond to attacks on the devices.

To enable the analysis of this data using process mining techniques, I would suggest to consider the combination of a time window ID ( __time_window_id__ ) and __SYSCALL_pid__ values as _cases_ and combinations of __SYSCALL_syscall__, __SYSCALL_success__, and maybe __PROCESS_uid__ values as _actions_. 

I transform the data by selecting __SYSCALL_timestamp__, __SYSCALL_pid__, __SYSCALL_success__, __PROCESS_uid__, and __SYSCALL_syscall__ columns. I also merge all data tables into a single table for more convenient processing. Finally, I divide the data into three parts:
  
  - _process_discovery_ part,   
  - _model_training_ part,
  - _test_data_ part.

```{r processed_data_loading, results='hide'}
load(file = "process_data_v2.RData")

process_discovery_data[SYSCALL_success == "", SYSCALL_success := "NA"]
model_training_data[SYSCALL_success == "", SYSCALL_success := "NA"]
test_data[SYSCALL_success == "", SYSCALL_success := "NA"]

setkey(process_discovery_data, time_window_id, SYSCALL_timestamp)
setkey(model_training_data, time_window_id, SYSCALL_timestamp)
setkey(test_data, time_window_id, SYSCALL_timestamp)
```

```{r bupar_experim, warning=FALSE, fig.hold='hold', out.width="100%", fig.width=12}
eventlog_data <- eventlog(as.data.frame(process_discovery_data),
                          case_id = c("time_window_id", "SYSCALL_pid"),
                          timestamp = "SYSCALL_timestamp",
                          activity_id = c("PROCESS_uid", "SYSCALL_syscall", "SYSCALL_success"),
                          activity_instance_id = c("time_window_id", "SYSCALL_pid", "PROCESS_uid", 
                                                   "SYSCALL_syscall", "SYSCALL_success", "SYSCALL_timestamp"),
                          resource_id = c("PROCESS_uid"),
                          lifecycle_id = "is_attack",
                          order = "alphabetical"
                          )

eventlog_data

trace_data <- traces(eventlog_data)
trace_data

frequent_traces <- filter_trace_frequency(eventlog_data, percentage = .8)
frequent_traces

attack_traces <- filter_lifecycle_presence(eventlog_data, lifecycles = "TRUE", method = "all")
attack_traces
```
```{r ploting_variants_1, warning=FALSE, fig.hold='hold', out.width="100%", fig.width=18}
flow_plot <- process_map(frequent_traces, type = frequency("relative"))
flow_plot

frequent_attack_traces <- filter_trace_frequency(attack_traces, percentage = .8)
attacks_flow_plot <- process_map(frequent_attack_traces, type = frequency("relative"))
attacks_flow_plot

variant_viz <- trace_explorer(eventlog_data, coverage = 0.5)
variant_viz
```

```{r compacting_traces}
eventlog_data_dt <- as.data.table(eventlog_data)

unique_action_ids <- eventlog_data_dt[, unique(PROCESS_uid_SYSCALL_syscall_SYSCALL_success)]
trace_dt <- eventlog_data_dt[, 
                             .(trace = paste(PROCESS_uid_SYSCALL_syscall_SYSCALL_success, 
                                             collapse = ","),
                               trace_length = .N),
                             by = time_window_id_SYSCALL_pid]

dim(trace_dt)
trace_dt[, uniqueN(trace)]

trace_dt <- compact_traces(trace_dt, unique_action_ids, 
                           show_progress = FALSE)
```

```{r clustering_traces, fig.hold='hold', out.width="100%", fig.width=7, fig.height=6}
normalized_levenshtein_dist <- function(x, y) {
  ldist <- proxy::dist(list(x), list(y), method = "Levenshtein")
  as.numeric(ldist)/(length(x) + length(y))
}

dist_matrix <- proxy::dist(strsplit(trace_dt[, unique(compacted_trace)], ","), 
                           method = normalized_levenshtein_dist)

hclustering <- hclust(dist_matrix, method = "ward.D")

mds_embedds <- cmdscale(dist_matrix, k = 2)
plot(mds_embedds, col = cutree(hclustering, k = 5), 
     xlab = "latent dim 1", 
     ylab = "latent dim 2",
     main = "Multidimensional scaling of trace variants")
save(dist_matrix, mds_embedds, file = "variant_distance_matrix.RData")

fig1 <- ggplot(data.table(mds_embedds), 
               aes(x=V1, y=V2, colour = factor(cutree(hclustering, k = 5)))) +
  geom_point() + 
  labs(x = "latent dim 1", y = "latent dim 2", colour = "group", 
       title = "Multidimensional scaling of trace variants")
fig1
```

```{r adding_attacks, fig.hold='hold', out.width="100%", fig.width=7, fig.height=6}
process_discovery_data[, time_window_id_SYSCALL_pid := paste0(time_window_id, "_", SYSCALL_pid)]
trace_dt <- trace_dt[process_discovery_data[, .(attack = is_attack[1]), 
                                            by = time_window_id_SYSCALL_pid], 
                     on = "time_window_id_SYSCALL_pid"]

global_mean <- trace_dt[, mean(attack)]
variant_dt <- trace_dt[, .(attack_prob = (sum(attack) + global_mean)/(.N + 1),
                           n_of_traces = .N), 
                       by = compacted_trace]

# here I'm relying on the assumption about the same ordering of variants - might be risky
variant_dt[, cluster_id := cutree(hclustering, k = 5)]


fig2 <- ggplot(data.table(mds_embedds), aes(x=V1, y=V2, 
                                            colour = variant_dt[, attack_prob], 
                                            #shape = factor(variant_dt[, cluster_id]),
                                            size = variant_dt[, log(n_of_traces)]
                                            )) +
  geom_point() + 
  scale_color_gradient2(midpoint=0.5, low="blue", mid="white",
                        high="red", space ="Lab" ) +
  labs(x = "latent dim 1", y = "latent dim 2", colour = "attack prob", size = "log(#traces)",
       title = "Multidimensional scaling of trace variants")
fig2
```


```{r selecting_cluster_reps, fig.hold='hold', out.width="100%", fig.width=7, fig.height=6}
dist_array <- as.matrix(dist_matrix)

variant_dt[, distance_to_cluster_members := 
              {sapply(.I, function(index) {
                            id = variant_dt[index, cluster_id]; 
                            sum(dist_array[index, variant_dt[, which(cluster_id == id)]] * 
                                variant_dt[cluster_id == id, n_of_traces])
                          })
              }]

# selecting cluster representatives
n_of_reps <- 5
cluster_reps <- variant_dt[, {id = first(order(distance_to_cluster_members), n_of_reps); 
                              .(index = .I[id],
                                n_of_traces = n_of_traces[id], 
                                attack_prob = attack_prob[id],
                                distance_to_cluster_members = distance_to_cluster_members[id]
                              )},
                           by = cluster_id]

fig3 <- ggplot(data.table(mds_embedds), aes(x=V1, y=V2, 
                                            colour = variant_dt[, attack_prob], 
                                            #shape = factor(variant_dt[, cluster_id]),
                                            size = variant_dt[, log(n_of_traces)]
                                            )) +
  geom_point() + 
  scale_color_gradient2(midpoint=0.5, low="blue", mid="white",
                        high="red", space ="Lab" ) +
  geom_point(data = data.table(mds_embedds[cluster_reps[, index], ]),
             color = variant_dt[cluster_reps[, index], factor(cluster_id)], 
             size = 2) + 
  labs(x = "latent dim 1", y = "latent dim 2", colour = "attack prob", size = "log(#traces)",
       title = "Visualization of variants with marked cluster representatives")
fig3

# selecting the largest variants
n_of_largest <- 5
largest_variants <- variant_dt[, {id = last(order(n_of_traces), n_of_largest); 
                                .(index = .I[id],
                                  n_of_traces = n_of_traces[id], 
                                  attack_prob = attack_prob[id],
                                  distance_to_cluster_members = distance_to_cluster_members[id]
                                )},
                              by = cluster_id]

fig4 <- ggplot(data.table(mds_embedds), aes(x=V1, y=V2, 
                                            colour = variant_dt[, attack_prob], 
                                            size = variant_dt[, log(n_of_traces)]
                                            )) +
  geom_point() + 
  scale_color_gradient2(midpoint=0.5, low="blue", mid="white",
                        high="red", space ="Lab" ) +
  geom_point(data = data.table(mds_embedds[largest_variants[, index], ]),
             color = variant_dt[largest_variants[, index], factor(cluster_id)], 
             size = 2) + 
  labs(x = "latent dim 1", y = "latent dim 2", colour = "attack prob", size = "log(#traces)",
       title = "Visualization of variants with marked largest variants for each cluster")
fig4

# selecting the largest variants
n_of_extreme_attack_probs <- 5
min_trace_count <- 10
extreme_variants <- variant_dt[n_of_traces > min_trace_count, 
                               {id = order(attack_prob); 
                                id = c(first(id, n_of_extreme_attack_probs), 
                                       last(id, n_of_extreme_attack_probs)); 
                              .(index = .I[id],
                                n_of_traces = n_of_traces[id], 
                                attack_prob = attack_prob[id],
                                distance_to_cluster_members = distance_to_cluster_members[id]
                              )},
                           by = .(cluster_id)]

fig5 <- ggplot(data.table(mds_embedds), aes(x=V1, y=V2, 
                                            colour = variant_dt[, attack_prob], 
                                            size = variant_dt[, log(n_of_traces)]
                                            )) +
  geom_point() + 
  scale_color_gradient2(midpoint=0.5, low="blue", mid="white",
                        high="red", space ="Lab" ) +
  geom_point(data = data.table(mds_embedds[extreme_variants[, index], ]),
             colour = variant_dt[extreme_variants[, index], factor(cluster_id)], 
             size = 2) + 
  labs(x = "latent dim 1", y = "latent dim 2", colour = "attack prob", size = "log(#traces)",
       title = "Visualization of variants with extreme attack probabilities")
fig5

unique(rbind(cluster_reps, largest_variants, extreme_variants))
save(variant_dt, cluster_reps, largest_variants, extreme_variants,
     file = "selected_variants.RData")
```




\  
\  


